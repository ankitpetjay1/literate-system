# Big Data with Big Query

**Course Topics**

1. BigQuery offers two services: Storage and Analytics
2. How BigQuery ML provides a data-to-ai lifecycle all in one place.
3. BigQuery ML project phases
4. BigQuery ML key commands.

---

### **Intro**

1. **BigQuery** is fully-managed data warehouse.

2. Data Warehouse is a large store containing terabytes and petabytes of data gathered from wide range of sources within an organization.

3. This data is used to guide management decisions.

4. Being fully managed means that BigQuery takes care of the underlying infrastrucutre.

5. Key Features:

   - Storage + Analytics. Can store petabytes of data. Can perform ML, Geospatial analysis and business intelligence.
   - Serverless
   - Flexible pay-as-you-go. Pay for query processed or use flat rate option.
   - Data encrypted at rest.
   - Built in ML. Can also export models from BigQuery to **Vertex AI** for seamless integration.

6. Typical Data warehouse solution architecture:

   1. The input data can be either real time or batch data.
   2. If it's streaming data, structured or unstructured, **Pub/Sub** is needed to digest the data.
   3. If it's batch data it can be directly uploaded to cloud storage.
   4. After that both pipelines lead to **Dataflow** where we extract transform and load the data.
   5. **BigQuery** sits in the middle which is the common staging. It links data processing and data access through analytics. The job of analytics engine of BigQuery is to ingest processed data and analyze it. Post that possibly output the data to either Business Intelligence tools bucket or AI/ML tools.
   6. Business Intelligence tools comprise of **Looker, Data Studio, Tableau, Google Sheets**
   7. AI/ML tools comprise of **AutoML, Vertex AI workbench**

<br>

### **Storage and Analytics**

1. BigQuery provides two services _Storage_ and _Analytical engine_.
2. Both are connected by Google's highspeed internal network.
3. Can ingest data from various sources
   - Internal: Within BigQuery
   - External: Other google cloud storage services.
     > Using Dataflow to process data before streaming into BigQuery can remove inconsistency.
   - Muti-Cloud data: AWS or Azure
   - Public datasets: Marketplace
4. Patterns to loads data into BigQuery:
   - Batch load
   - Streaming
   - Generated data
5. BigQuery can run analytical queries over large datasets.
   - Query terabytes in seconds
   - Query petabytes in minutes.
6. Supports following features:
   - Ad hoc analysis by running SQL queries on large datasets.
   - Geospatial analysis
   - ML models using SQL.
   - Buildign BI dashboards.
7. Can execute queries as needed or in batches i.e.. queries start when resources are available.

<br>

### **BigQuery ML**

Build and training models can be very time intensive.

1. You must first export data from your datastore into an IDE.

2. Transform the data and perform feature engineering.

3. Build the model in Tensorflow and train it locally or on a VM.

4. To improve performance, you need to get more data and create new features.

5. And cycle repeats.

<br>

**BigQuery ML**

Now you can create and execute ML models on your structured datasets in BigQuery using SQL queries.

1. Step 1: Create a model with SQL statement.
2. Step 2: Write a SQL prediction query and invoke `ml.PREDICT`
3. You now have a model. Additional activities may include evaluating a model.
4. Training a model can extend to _Hyperparameters_ which let you tune the model to achieve best results. BigQuery can automatically tune hyperparameters or you can manually control hyperparameters.
5. Google BigQuery ML supports 2 models:
   - _Supervised models_
     - Classify data? Use **Logistic regression**.
     - Predict a number? Use **Linear regression**.
   - _Unsupervised models_
     - Identify patterns and clusters? Use Cluster analysis.
6. Also supports ML Ops.
   - Importing Tensorflow models
   - Exporting models from BigQuery ML
   - Hyperparameter tuning using Cloud AI Vizier.

### **Phases of a BigQuery ML Project **

1. Extract, Transform and load data into
   BigQuery.

   - SQL joins help in enriching your existing data warehouse with other data sources.

2. Select and preprocess features.

   - Use SQL to create training dataset for the model to learn from.
   - BigQuery ML can do some preprocessing like one-hot encoding of categorical variables.

3. Create the model inside BigQuery.

   - Using the `CREATE MODEL` command in BigQuery.
   - Give model a name, specify type, provide label and pass SQL query with training dataset.

4. Evaluate the performance of the trained model.

   - After model is trained use the query `ML.EVALUATE` to evaluate the performance of the trained model.
   - Analyze metrics like RMSE, forecasting models and area under the curve, accuracy, precision, recall for classification models.

5. Use the model to make predictions.
   - Use command `ml.PREDICT` on new trained model to return predictions and the model's confidence in those predictions.
   - A label field with predicted added to the field name will display your model's predictions.

### **Key commands in BigQuery**

1. You can create a model with just the `CREATE MODEL` command.

   - If you want to overwrite an existing model use the `CREATE OR REPLACE MODEL`.
   - Models have options. The most important and the only one required is the `model_type`.

2. You can inspect what the model learned with the `ML.WEIGHTS` command and filtering on an input column.

   - The output of `ML.WEIGHTS` is a numerical value and each feature has a weight from -1 to 1.
   - The value indicates how important the feature is for predicting the result or label.
   - Zero means the feature isn't important for the prediction however if the number is closer to negative one or one then the feature is more important for predicting the result.

3. To evaluate the model's performance you can run an `ML.EVALUATE` command against a trained model.

   - You get different performance metrics depending on the model type.

4. If you want to make batch predictions you can use the `ML.PREDICT` command on a trained model and pass through the data set you want to make the prediction on.

**Supervised Models ML Commands**

1. Labels: Identify columns as labels or can specify under OPTIONS.

2. Features: Your model features are the data columns that are part of your `Select` statement after your `Create Model` statement. After a model is trained you can use the `ML.feature_info()` command to get statistics and metrics about the column for additional analysis.

3. Model Object: An object created in bigquery that resides in your BigQuery data set. You train many different models which will all be objects stored under your BigQuery data set much like your tables and views. Model objects can display information for when it was last updated or how many training runs it completed.

4. Model Types: Creating a new model is as easy as writing create model choosing a type and passing in a training data set. If you're predicting on a numeric field such as next year's sales consider _linear regression_ for forecasting if it's a discrete class like high medium low or spam or not spam consider using _logistic regression_ for classification

5. Training Progress: While the model is running and even after it's complete you can view training progress with `ML.TRAINING_INFO()`

6. Inspect Weights: To see what the model learned about the importance of each feature. The importance is indicated by the weight of each feature.

7. Evaluaton: You can see how well the model performed against its evaluation dataset by using `ML.EVALUATE`

8. Predictions: Lastly getting predictions is as simple as writing `ML.PREDICT` and referencing your model name and prediction data set.
